{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samarreguigui/AI_Ethik/blob/main/Roscoe_drop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will study the second point :identify specific cases where the LLM’s judgments\n",
        "differ from human judgments, and analyze the underlying reasons for these differences,\n",
        "including systematic biases such as preference for fluent or verbose outputs rather than\n",
        "task specific criteria."
      ],
      "metadata": {
        "id": "E4k-A9zTt-JE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Human annotators were provided with the full task instance while evaluating individual reasoning steps. To disentangle step level judgment behavior from task solving, we evaluate LLM judges under two conditions: a context free step only condition and a context aware condition that includes the full instance. This allows us to isolate stylistic judgment biases and assess the effect of contextual information."
      ],
      "metadata": {
        "id": "iRh877HL22d9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Without the instance context**"
      ],
      "metadata": {
        "id": "rtIV5Mhe225s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U openai\n"
      ],
      "metadata": {
        "id": "7CMXD-PoGPMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== STEP 1: LOAD ROSCOE-DROP-STEPWISE =====\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Path to your JSON file (adjust if needed)\n",
        "JSON_PATH = \"roscoe-drop-stepwise.json\"\n",
        "\n",
        "# 2. Load the JSON\n",
        "with open(JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# 3. Basic checks\n",
        "print(\"Top-level keys:\", list(data.keys()))\n",
        "print(\"Dataset name:\", data.get(\"dataset\"))\n",
        "print(\"Number of instances:\", len(data[\"instances\"]))\n",
        "\n",
        "# 4. Flatten instances into a DataFrame\n",
        "rows = []\n",
        "for inst in data[\"instances\"]:\n",
        "    inst_id = inst[\"id\"]\n",
        "    inst_text = inst[\"instance\"]\n",
        "    ann = inst[\"annotations\"]\n",
        "\n",
        "    row = {\n",
        "        \"id\": inst_id,\n",
        "        \"instance_text\": inst_text,\n",
        "    }\n",
        "\n",
        "    # Add majority human label for each metric (yes/no)\n",
        "    for metric_name, metric_info in ann.items():\n",
        "        row[f\"{metric_name}_majority\"] = metric_info[\"majority_human\"]\n",
        "\n",
        "    rows.append(row)\n",
        "\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "print(\"\\nColumns in DataFrame:\")\n",
        "print(df.columns.tolist())\n",
        "\n",
        "print(\"\\nFirst 3 rows:\")\n",
        "print(df.head(3))\n",
        "\n",
        "print(\"\\nLabel distribution for some metrics:\")\n",
        "for m in [\"Grammar\", \"Factuality\", \"Coherency and Logic\",\n",
        "          \"Final Answer\", \"Hallucination\"]:\n",
        "    col = f\"{m}_majority\"\n",
        "    if col in df.columns:\n",
        "        print(f\"\\nMetric: {m}\")\n",
        "        print(df[col].value_counts())\n"
      ],
      "metadata": {
        "id": "umBsmCQpZ6ZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# ===== helper: parse one instance into steps =====\n",
        "\n",
        "STEP_PATTERN = re.compile(r\"(Step\\s+\\d+\\s*-\\s*)(.*)\")\n",
        "\n",
        "def split_instance_into_steps(instance_text):\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "      context_block: everything before 'GENERATED RESPONSE:'\n",
        "      steps: list of (step_index, step_text)\n",
        "    \"\"\"\n",
        "    # Separate instruction/context from generated response\n",
        "    parts = instance_text.split(\"GENERATED RESPONSE:\")\n",
        "    if len(parts) != 2:\n",
        "        return instance_text, []  # fallback\n",
        "\n",
        "    context_block = parts[0]\n",
        "    gen_resp = parts[1]\n",
        "\n",
        "    steps = []\n",
        "    # Split by lines and collect those starting with 'Step'\n",
        "    for line in gen_resp.splitlines():\n",
        "        line = line.strip()\n",
        "        if line.startswith(\"JUDGE:\"):\n",
        "            break  # ignore judge segment\n",
        "        m = STEP_PATTERN.match(line)\n",
        "        if m:\n",
        "            prefix, text = m.groups()\n",
        "            # step number from prefix, e.g. \"Step 1 - \"\n",
        "            try:\n",
        "                step_num = int(re.findall(r\"\\d+\", prefix)[0])\n",
        "            except Exception:\n",
        "                step_num = None\n",
        "            steps.append((step_num, text.strip()))\n",
        "    return context_block, steps\n",
        "\n",
        "# ===== apply to all instances =====\n",
        "\n",
        "step_rows = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    inst_id = row[\"id\"]\n",
        "    inst_text = row[\"instance_text\"]\n",
        "\n",
        "    context_block, steps = split_instance_into_steps(inst_text)\n",
        "\n",
        "    # copy human majority labels for this instance\n",
        "    meta = {\n",
        "        \"id\": inst_id,\n",
        "        \"context_block\": context_block,\n",
        "    }\n",
        "    for col in df.columns:\n",
        "        if col.endswith(\"_majority\"):\n",
        "            meta[col] = row[col]\n",
        "\n",
        "    for step_num, step_text in steps:\n",
        "        step_row = meta.copy()\n",
        "        step_row[\"step_num\"] = step_num\n",
        "        step_row[\"step_text\"] = step_text\n",
        "        step_rows.append(step_row)\n",
        "\n",
        "steps_df = pd.DataFrame(step_rows)\n",
        "\n",
        "print(\"Num step-level rows:\", len(steps_df))\n",
        "print(\"\\nColumns:\")\n",
        "print(steps_df.columns.tolist())\n",
        "\n",
        "print(\"\\nSample steps:\")\n",
        "print(steps_df[[\"id\", \"step_num\", \"step_text\"]].head(5))\n"
      ],
      "metadata": {
        "id": "1u1vseBHaIml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import os, time\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"-\"\n",
        "\n",
        "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "JUDGE_MODEL = \"gpt-4o\""
      ],
      "metadata": {
        "id": "ViI_4yj1aPxp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we use the prompt t see if there is a problem. in the next implimentation we will take the human evaluation and create a column from the human_has_problem\n",
        "\n",
        "That was done to create one simple “human says this step is OK / not OK” label so it can be compared directly to the LLM’s single yes/no judgment.\n",
        "​\n",
        "\n",
        "Why combine metrics into one label\n",
        "ROSCOE gives many labels per step (Factuality, Coherency, Final Answer, Hallucination, Commonsense, Arithmetic, etc.).\n",
        "​\n",
        "\n",
        "Your LLM judge, however, was asked one question: “Does this step contain any reasoning or factual problem? yes/no.”\n",
        "\n",
        "To compare them, you need one human label of the same kind:\n",
        "\n"
      ],
      "metadata": {
        "id": "4uhZ6qcu0IOW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "JUDGE_SYSTEM_PROMPT = \"\"\"You are an expert reasoning evaluator.\n",
        "You see a context, a question, and ONE step from a model's explanation.\n",
        "\n",
        "Your task: decide if this step contains ANY problem that makes the reasoning incorrect or untrustworthy, such as:\n",
        "- factual errors\n",
        "- logical/coherence errors\n",
        "- incorrect final answer in this step\n",
        "- hallucinations\n",
        "- arithmetic or commonsense errors\n",
        "\n",
        "Ignore minor style issues like wording or politeness.\n",
        "Answer with exactly one word: 'yes' if there IS some problem in the step, 'no' if the step is fine.\n",
        "\"\"\"\n",
        "\n",
        "def build_step_prompt(row):\n",
        "    ctx = row[\"context_block\"]\n",
        "    step_num = row[\"step_num\"]\n",
        "    step_text = row[\"step_text\"]\n",
        "\n",
        "    user = f\"\"\"CONTEXT AND QUESTION:\n",
        "{ctx}\n",
        "\n",
        "STEP {step_num} TO EVALUATE:\n",
        "{step_text}\n",
        "\n",
        "Question for you:\n",
        "Does this step contain any reasoning or factual problems?\n",
        "Answer 'yes' or 'no'.\"\"\"\n",
        "    return user\n"
      ],
      "metadata": {
        "id": "7aZxQwVGaYoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test prompt :\n",
        "# Pick one row, e.g. first judged step\n",
        "example_row = analysis_df.iloc[0]\n",
        "\n",
        "print(\"=== CONTEXT BLOCK ===\")\n",
        "print(example_row[\"context_block\"])\n",
        "print(\"\\n=== STEP TEXT ===\")\n",
        "print(f\"Step {example_row['step_num']}: {example_row['step_text']}\")\n",
        "\n",
        "print(\"\\n=== FULL USER PROMPT SENT TO LLM ===\")\n",
        "print(build_step_prompt(example_row))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA8TvrU6hFd8",
        "outputId": "87e5d2f9-760e-4a87-c5de-55ce17495a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== CONTEXT BLOCK ===\n",
            "For this task, you will be shown a CONTEXT with a \"Situation\" and a \"Claim\" about that \"Situation\". The \"Claim\" may or may not be supported by the \"Situation\". The Correct Relationship between the \"Claim\" and the \"Situation\" is provided.\n",
            "\n",
            "You will be shown a GENERATED RESPONSE generated from a bot, asked the question\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "You will be asked to judge the individual STEPS within the GENERATED RESPONSE. Interpret the questions to the best of your ability. Sometimes the generated response will refer to the \"Situation\" as a \"Premise\" and the \"Claim\" as a \"Hypothesis\". It will oftentimes be faster to read the \"Claim\" before the \"Situation\".\n",
            "\n",
            "CONTEXT:\n",
            "Situation (Premise): Hoping to rebound from their home loss to the Vikings, the Cardinals flew to Gillette Stadium for a Week 16 interconference duel with the New England Patriots. Arizona would trail early in the first quarter as Patriots running back LaMont Jordan got a one-yard and a three-yard touchdown run. The Cardinals' east coast struggles continued in the second quarter as quarterback Matt Cassel completed a 15-yard touchdown pass to running back Kevin Faulk and an 11-yard touchdown pass to wide receiver Wes Welker, followed by kicker Stephen Gostkowski's 38-yard field goal. In the third quarter, Arizona's deficit continued to climb as Cassel completed a 76-yard touchdown pass to wide receiver Randy Moss, followed by Gostkowski's 35- and 24-yard field goal. In the fourth quarter, New England concluded its domination with Gostkowski's 30-yard field goal. The Cardinals would then get a meaningless touchdown as quarterback Matt Leinart completed a 78-yard touchdown pass to wide receiver Larry Fitzgerald. Original starting quarterback Kurt Warner (6/18 for 30 yards) was pulled in the third quarter via coach's decision. who was starter QB for cardinal's?\n",
            "\n",
            "Claim (Hypothesis): Kurt Warner\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "Correct Relationship (Yes or No): yes\n",
            "\n",
            "\n",
            "\n",
            "=== STEP TEXT ===\n",
            "Step 1: Warner was the starting quarterback for the Cardinals, but was pulled in the third quarter.\n",
            "\n",
            "=== FULL USER PROMPT SENT TO LLM ===\n",
            "CONTEXT AND QUESTION:\n",
            "For this task, you will be shown a CONTEXT with a \"Situation\" and a \"Claim\" about that \"Situation\". The \"Claim\" may or may not be supported by the \"Situation\". The Correct Relationship between the \"Claim\" and the \"Situation\" is provided.\n",
            "\n",
            "You will be shown a GENERATED RESPONSE generated from a bot, asked the question\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "You will be asked to judge the individual STEPS within the GENERATED RESPONSE. Interpret the questions to the best of your ability. Sometimes the generated response will refer to the \"Situation\" as a \"Premise\" and the \"Claim\" as a \"Hypothesis\". It will oftentimes be faster to read the \"Claim\" before the \"Situation\".\n",
            "\n",
            "CONTEXT:\n",
            "Situation (Premise): Hoping to rebound from their home loss to the Vikings, the Cardinals flew to Gillette Stadium for a Week 16 interconference duel with the New England Patriots. Arizona would trail early in the first quarter as Patriots running back LaMont Jordan got a one-yard and a three-yard touchdown run. The Cardinals' east coast struggles continued in the second quarter as quarterback Matt Cassel completed a 15-yard touchdown pass to running back Kevin Faulk and an 11-yard touchdown pass to wide receiver Wes Welker, followed by kicker Stephen Gostkowski's 38-yard field goal. In the third quarter, Arizona's deficit continued to climb as Cassel completed a 76-yard touchdown pass to wide receiver Randy Moss, followed by Gostkowski's 35- and 24-yard field goal. In the fourth quarter, New England concluded its domination with Gostkowski's 30-yard field goal. The Cardinals would then get a meaningless touchdown as quarterback Matt Leinart completed a 78-yard touchdown pass to wide receiver Larry Fitzgerald. Original starting quarterback Kurt Warner (6/18 for 30 yards) was pulled in the third quarter via coach's decision. who was starter QB for cardinal's?\n",
            "\n",
            "Claim (Hypothesis): Kurt Warner\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "Correct Relationship (Yes or No): yes\n",
            "\n",
            "\n",
            "\n",
            "STEP 1 TO EVALUATE:\n",
            "Warner was the starting quarterback for the Cardinals, but was pulled in the third quarter.\n",
            "\n",
            "Question for you:\n",
            "Does this step contain any reasoning or factual problems?\n",
            "Answer 'yes' or 'no'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def judge_step(row, retries=3, sleep_sec=2):\n",
        "    prompt = build_step_prompt(row)\n",
        "    for _ in range(retries):\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=JUDGE_MODEL,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": JUDGE_SYSTEM_PROMPT},\n",
        "                    {\"role\": \"user\", \"content\": prompt},\n",
        "                ],\n",
        "                temperature=0.0,\n",
        "            )\n",
        "            txt = resp.choices[0].message.content.strip().lower()\n",
        "            time.sleep(0.5)\n",
        "\n",
        "            if \"yes\" in txt and \"no\" not in txt:\n",
        "                return \"yes\"\n",
        "            if \"no\" in txt and \"yes\" not in txt:\n",
        "                return \"no\"\n",
        "        except Exception as e:\n",
        "            print(\"Error, retrying:\", e)\n",
        "            time.sleep(sleep_sec)\n",
        "    return None\n"
      ],
      "metadata": {
        "id": "PebtYZUOap48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_STEPS_TO_JUDGE = 200   # increase later if needed\n",
        "\n",
        "subset = steps_df.sample(n=min(MAX_STEPS_TO_JUDGE, len(steps_df)), random_state=0).copy()\n",
        "\n",
        "tqdm.pandas()\n",
        "subset[\"llm_problem\"] = subset.progress_apply(judge_step, axis=1)\n",
        "\n",
        "print(\"\\nValue counts of LLM judgments:\")\n",
        "print(subset[\"llm_problem\"].value_counts(dropna=False))\n",
        "\n",
        "# Keep only rows where the LLM gave a clear yes/no\n",
        "subset = subset.dropna(subset=[\"llm_problem\"])\n"
      ],
      "metadata": {
        "id": "SfZ6lXuGas7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        },
        "id": "pEDxKvzwcPA3",
        "outputId": "89a904bf-c769-4ce2-fa88-ddb03e46d921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       id                                      context_block Grammar_majority  \\\n",
              "805   305  For this task, you will be shown a CONTEXT wit...               no   \n",
              "646   239  For this task, you will be shown a CONTEXT wit...               no   \n",
              "500   172  For this task, you will be shown a CONTEXT wit...               no   \n",
              "204    85  For this task, you will be shown a CONTEXT wit...               no   \n",
              "1208  417  For this task, you will be shown a CONTEXT wit...               no   \n",
              "...   ...                                                ...              ...   \n",
              "467   168  For this task, you will be shown a CONTEXT wit...               no   \n",
              "425   153  For this task, you will be shown a CONTEXT wit...               no   \n",
              "459   167  For this task, you will be shown a CONTEXT wit...               no   \n",
              "513   174  For this task, you will be shown a CONTEXT wit...               no   \n",
              "320   117  For this task, you will be shown a CONTEXT wit...               no   \n",
              "\n",
              "     Factuality_majority Coherency and Logic_majority Final Answer_majority  \\\n",
              "805                   no                           no                    no   \n",
              "646                   no                           no                    no   \n",
              "500                   no                           no                    no   \n",
              "204                   no                           no                    no   \n",
              "1208                  no                           no                    no   \n",
              "...                  ...                          ...                   ...   \n",
              "467                   no                           no                    no   \n",
              "425                   no                           no                    no   \n",
              "459                   no                           no                    no   \n",
              "513                   no                           no                    no   \n",
              "320                   no                           no                    no   \n",
              "\n",
              "     Hallucination_majority Redundancy_majority Repetition_majority  \\\n",
              "805                      no                  no                  no   \n",
              "646                      no                  no                  no   \n",
              "500                      no                  no                  no   \n",
              "204                      no                  no                  no   \n",
              "1208                     no                  no                  no   \n",
              "...                     ...                 ...                 ...   \n",
              "467                      no                  no                  no   \n",
              "425                      no                  no                  no   \n",
              "459                      no                  no                  no   \n",
              "513                      no                  no                  no   \n",
              "320                      no                 yes                  no   \n",
              "\n",
              "     Commonsense_majority Arithmetic_majority  step_num  \\\n",
              "805                    no                  no         1   \n",
              "646                    no                  no         1   \n",
              "500                    no                  no         5   \n",
              "204                    no                  no         1   \n",
              "1208                   no                  no         2   \n",
              "...                   ...                 ...       ...   \n",
              "467                    no                  no         4   \n",
              "425                    no                  no         1   \n",
              "459                    no                  no         4   \n",
              "513                    no                  no         2   \n",
              "320                    no                  no         5   \n",
              "\n",
              "                                              step_text llm_problem  \n",
              "805   Warner was the starting quarterback for the Ca...          no  \n",
              "646          On 10 August 1919 a cease-fire was signed.          no  \n",
              "500   12.73675 people- 5.3% Danish people= 12.177 pe...         yes  \n",
              "204   Bills went home for their last home game of th...          no  \n",
              "1208                                   The answer is 3.          no  \n",
              "...                                                 ...         ...  \n",
              "467   14.225 people- 10.7% United States= 12.73675 p...         yes  \n",
              "425   It took the Singapore National Olympic Council...          no  \n",
              "459   14.225 people- 10.7% United States= 12.73675 p...         yes  \n",
              "513       19.357 people- 16.5% Germans= 16.1185 people.         yes  \n",
              "320   Following the Kuwait-Najd War, Ibn Saud impose...          no  \n",
              "\n",
              "[200 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b3f9599-94c2-4e57-91d9-17930a6f03a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>context_block</th>\n",
              "      <th>Grammar_majority</th>\n",
              "      <th>Factuality_majority</th>\n",
              "      <th>Coherency and Logic_majority</th>\n",
              "      <th>Final Answer_majority</th>\n",
              "      <th>Hallucination_majority</th>\n",
              "      <th>Redundancy_majority</th>\n",
              "      <th>Repetition_majority</th>\n",
              "      <th>Commonsense_majority</th>\n",
              "      <th>Arithmetic_majority</th>\n",
              "      <th>step_num</th>\n",
              "      <th>step_text</th>\n",
              "      <th>llm_problem</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>805</th>\n",
              "      <td>305</td>\n",
              "      <td>For this task, you will be shown a CONTEXT wit...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>Warner was the starting quarterback for the Ca...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>646</th>\n",
              "      <td>239</td>\n",
              "      <td>For this task, you will be shown a CONTEXT wit...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>On 10 August 1919 a cease-fire was signed.</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>172</td>\n",
              "      <td>For this task, you will be shown a CONTEXT wit...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>12.73675 people- 5.3% Danish people= 12.177 pe...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>85</td>\n",
              "      <td>For this task, you will be shown a CONTEXT wit...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>Bills went home for their last home game of th...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1208</th>\n",
              "      <td>417</td>\n",
              "      <td>For this task, you will be shown a CONTEXT wit...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>The answer is 3.</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>168</td>\n",
              "      <td>For this task, you will be shown a CONTEXT wit...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>14.225 people- 10.7% United States= 12.73675 p...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>153</td>\n",
              "      <td>For this task, you will be shown a CONTEXT wit...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>It took the Singapore National Olympic Council...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>167</td>\n",
              "      <td>For this task, you will be shown a CONTEXT wit...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>4</td>\n",
              "      <td>14.225 people- 10.7% United States= 12.73675 p...</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>174</td>\n",
              "      <td>For this task, you will be shown a CONTEXT wit...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>19.357 people- 16.5% Germans= 16.1185 people.</td>\n",
              "      <td>yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>117</td>\n",
              "      <td>For this task, you will be shown a CONTEXT wit...</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>5</td>\n",
              "      <td>Following the Kuwait-Najd War, Ibn Saud impose...</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 14 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b3f9599-94c2-4e57-91d9-17930a6f03a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5b3f9599-94c2-4e57-91d9-17930a6f03a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5b3f9599-94c2-4e57-91d9-17930a6f03a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-86a34f3f-2ff1-4453-82fc-8f3fa43eee1e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-86a34f3f-2ff1-4453-82fc-8f3fa43eee1e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-86a34f3f-2ff1-4453-82fc-8f3fa43eee1e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_222f09a6-bb20-4b5e-8e42-1078da79060a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('subset')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_222f09a6-bb20-4b5e-8e42-1078da79060a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('subset');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "subset",
              "summary": "{\n  \"name\": \"subset\",\n  \"rows\": 200,\n  \"fields\": [\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 130,\n        \"min\": 1,\n        \"max\": 449,\n        \"num_unique_values\": 159,\n        \"samples\": [\n          285,\n          247,\n          139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"context_block\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 104,\n        \"samples\": [\n          \"For this task, you will be shown a CONTEXT with a \\\"Situation\\\" and a \\\"Claim\\\" about that \\\"Situation\\\". The \\\"Claim\\\" may or may not be supported by the \\\"Situation\\\". The Correct Relationship between the \\\"Claim\\\" and the \\\"Situation\\\" is provided.\\n\\nYou will be shown a GENERATED RESPONSE generated from a bot, asked the question\\n\\nIs the Claim supported by the Situation?\\n\\nYou will be asked to judge the individual STEPS within the GENERATED RESPONSE. Interpret the questions to the best of your ability. Sometimes the generated response will refer to the \\\"Situation\\\" as a \\\"Premise\\\" and the \\\"Claim\\\" as a \\\"Hypothesis\\\". It will oftentimes be faster to read the \\\"Claim\\\" before the \\\"Situation\\\".\\n\\nCONTEXT:\\nSituation (Premise): Meeting for the first time since Super Bowl XLVI, the Giants host the undefeated Patriots. Commissioner Roger Goodell was in attendance. The Giants looked to stop the streaking Patriots in a game where both teams saw touchdowns wiped out on penalties. The Giants trailed by 2 at the two-minute warning, and on second down Eli Manning tossed a pass in the end zone to Odell Beckham Jr.. Beckham appeared to have the catch, but as he brought the ball up in celebration, it was knocked out by Malcolm Butler in a play eerily similar to a drop by Lee Evans in the closing seconds of the 2011 AFC Championship Game. Manning scrambled for a loss on third down, and Josh Brown kicked the go-ahead field goal to give New York a lead. However, a last second game-winning field goal by the Patriots kicker Stephen Gostkowski ended the Giants hopes. Although he was cleared to play, Victor Cruz, a day later, announced he would not play this season as he underwent surgery to repair an injured left calf. How many games had the Patriots lost all season?\\n\\nClaim (Hypothesis): 0\\n\\nIs the Claim supported by the Situation?\\n\\nCorrect Relationship (Yes or No): yes\\n\\n\",\n          \"For this task, you will be shown a CONTEXT with a \\\"Situation\\\" and a \\\"Claim\\\" about that \\\"Situation\\\". The \\\"Claim\\\" may or may not be supported by the \\\"Situation\\\". The Correct Relationship between the \\\"Claim\\\" and the \\\"Situation\\\" is provided.\\n\\nYou will be shown a GENERATED RESPONSE generated from a bot, asked the question\\n\\nIs the Claim supported by the Situation?\\n\\nYou will be asked to judge the individual STEPS within the GENERATED RESPONSE. Interpret the questions to the best of your ability. Sometimes the generated response will refer to the \\\"Situation\\\" as a \\\"Premise\\\" and the \\\"Claim\\\" as a \\\"Hypothesis\\\". It will oftentimes be faster to read the \\\"Claim\\\" before the \\\"Situation\\\".\\n\\nCONTEXT:\\nSituation (Premise): The Buccaneers traveled to M&T Bank Stadium to face the Baltimore Ravens. In a largely defensive game, the teams traded field goals in the second quarter. The game was tied 3-3 with 4:32 remaining in the first half. Quarterback Joe Flacco struck quickly, however, completing touchdown passes of 65 yards and 10 yards, to Todd Heap and Derrick Mason respectively, just before half time. Trailing 17-3 with about three minutes left in the game, Josh Freeman completed a 5-yard touchdown pass to Kellen Winslow. The Buccaneers were unable to get the ball back on offense, and fell by a score of 17-10. How many total points did Tampa Bay score in the game?\\n\\nClaim (Hypothesis): 10\\n\\nIs the Claim supported by the Situation?\\n\\nCorrect Relationship (Yes or No): yes\\n\\n\",\n          \"For this task, you will be shown a CONTEXT with a \\\"Situation\\\" and a \\\"Claim\\\" about that \\\"Situation\\\". The \\\"Claim\\\" may or may not be supported by the \\\"Situation\\\". The Correct Relationship between the \\\"Claim\\\" and the \\\"Situation\\\" is provided.\\n\\nYou will be shown a GENERATED RESPONSE generated from a bot, asked the question\\n\\nIs the Claim supported by the Situation?\\n\\nYou will be asked to judge the individual STEPS within the GENERATED RESPONSE. Interpret the questions to the best of your ability. Sometimes the generated response will refer to the \\\"Situation\\\" as a \\\"Premise\\\" and the \\\"Claim\\\" as a \\\"Hypothesis\\\". It will oftentimes be faster to read the \\\"Claim\\\" before the \\\"Situation\\\".\\n\\nCONTEXT:\\nSituation (Premise): The total number of active military personnel in the Croatian Armed Forces stands at 14,506 and 6,000 reserves working in various service branches of the armed forces. In May 2016, Armed Forces had 16,019 members, of which 14,506 were active military personnel and 1,513 civil servants. Of the 14,506 active military personnel, 3,183 were officers, 5,389 non-commissioned officers, 5,393 soldiers, 520 military specialists, 337 civil servants and 1,176 other employees. How many more non commissioned officers than military specialists were in the Croatian Armed Forces in 2016?\\n\\nClaim (Hypothesis): 4869\\n\\nIs the Claim supported by the Situation?\\n\\nCorrect Relationship (Yes or No): yes\\n\\n\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Grammar_majority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Factuality_majority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Coherency and Logic_majority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Final Answer_majority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hallucination_majority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Redundancy_majority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Repetition_majority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Commonsense_majority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Arithmetic_majority\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step_num\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          8\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"step_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 127,\n        \"samples\": [\n          \"Guadalajara was retaken by christian forces in 1085 and received their first fuero in 1133.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"llm_problem\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#human_problem and llm_problem_bin\n",
        "#Collapsed these metrics into one binary label human_problem = 1 if any of those metrics had majority “yes” (i.e. humans saw some issue in the step), else 0\n",
        "ERROR_METRICS = [\n",
        "    \"Factuality_majority\",\n",
        "    \"Coherency and Logic_majority\",\n",
        "    \"Final Answer_majority\",\n",
        "    \"Hallucination_majority\",\n",
        "    \"Commonsense_majority\",\n",
        "    \"Arithmetic_majority\",\n",
        "]\n",
        "\n",
        "def human_has_problem(row):\n",
        "    for col in ERROR_METRICS:\n",
        "        if col in row and row[col] == \"yes\":\n",
        "            return 1\n",
        "    return 0\n",
        "\n",
        "subset[\"human_problem\"] = subset.apply(human_has_problem, axis=1)\n",
        "subset[\"llm_problem_bin\"] = subset[\"llm_problem\"].map({\"yes\": 1, \"no\": 0})\n",
        "\n",
        "print(pd.crosstab(subset[\"human_problem\"], subset[\"llm_problem_bin\"],\n",
        "                  rownames=[\"human\"], colnames=[\"llm\"]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PQ0bpT2ccWg",
        "outputId": "4c7499dc-0a50-456b-942b-0c65d7ea2fb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "llm      0   1\n",
            "human         \n",
            "0      130  46\n",
            "1       12  12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "analysis_df = subset.copy()\n",
        "analysis_df[\"agree\"] = (analysis_df[\"human_problem\"] == analysis_df[\"llm_problem_bin\"]).astype(int)\n",
        "\n",
        "def num_tokens(text):\n",
        "    return len(enc.encode(text or \"\"))\n",
        "\n",
        "analysis_df[\"step_len\"] = analysis_df[\"step_text\"].apply(lambda x: num_tokens(str(x)))\n",
        "\n",
        "print(\"\\nAgreement rate:\", analysis_df[\"agree\"].mean())\n",
        "print(\"\\nAvg length by agreement:\")\n",
        "print(analysis_df.groupby(\"agree\")[\"step_len\"].mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfGNIXHBc3vV",
        "outputId": "2ba41eda-4208-4557-8222-0391cc63428a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Agreement rate: 0.71\n",
            "\n",
            "Avg length by agreement:\n",
            "agree\n",
            "0    16.362069\n",
            "1    18.366197\n",
            "Name: step_len, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, on average, the steps where the LLM and humans disagree are slightly shorter than those where they agree. This suggests that the model might be somewhat more reliable on longer steps (perhaps because it has more information to work with), while shorter steps leave more room for it to misjudge whether there is a problem."
      ],
      "metadata": {
        "id": "GqlH0KmUdptO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **test whether your LLM judge is biased toward style instead of correctness**"
      ],
      "metadata": {
        "id": "eI9W4-cXeFkw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers\n"
      ],
      "metadata": {
        "id": "aKk7vJ3dehEz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#1. Compare average fluency in agree vs disagree by computing a fluency score\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "FLU_MODEL_NAME = \"gpt2\"   # small, just for a rough fluency proxy\n",
        "\n",
        "flu_tokenizer = AutoTokenizer.from_pretrained(FLU_MODEL_NAME)\n",
        "flu_model = AutoModelForCausalLM.from_pretrained(FLU_MODEL_NAME)\n",
        "flu_model.eval()\n",
        "if torch.cuda.is_available():\n",
        "    flu_model.to(\"cuda\")\n",
        "\n",
        "def avg_nll(text):\n",
        "    text = str(text)\n",
        "    if not text.strip():\n",
        "        return 0.0\n",
        "    inputs = flu_tokenizer(text, return_tensors=\"pt\")\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = {k: v.to(\"cuda\") for k, v in inputs.items()}\n",
        "    with torch.no_grad():\n",
        "        out = flu_model(**inputs, labels=inputs[\"input_ids\"])\n",
        "    return out.loss.item()   # average per token\n",
        "\n",
        "analysis_df[\"nll\"] = analysis_df[\"step_text\"].apply(avg_nll)\n",
        "analysis_df[\"fluency\"] = -analysis_df[\"nll\"]   # higher = more fluent\n",
        "\n",
        "print(\"\\nFluency stats by agreement:\")\n",
        "print(analysis_df.groupby(\"agree\")[\"fluency\"].mean())\n",
        "\n"
      ],
      "metadata": {
        "id": "-HOrS0ECeJvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analysis_df"
      ],
      "metadata": {
        "id": "wtA6JSTDi4iN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " disagreeing steps are less fluent on average than agreeing steps\n",
        " Your main hypothesis was:\n",
        "\n",
        "The judge might **over‑trust very fluent, verbose steps even when they are wrong.\n",
        "\n",
        "If that were happening strongly, you would expect many human‑marked error steps that are highly fluent, where the judge says “no problem.”\n",
        "The aggregate stats you looked at do not show higher fluency on disagreement overall; instead, disagreements are less fluent on average."
      ],
      "metadata": {
        "id": "FJivVVzkfoEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Only steps where humans say there IS a problem\n",
        "err_df = analysis_df[analysis_df[\"human_problem\"] == 1].copy()\n",
        "\n",
        "print(\"\\nFluency for human-error steps:\")\n",
        "print(err_df.groupby(\"llm_problem_bin\")[\"fluency\"].mean())\n",
        "print(\"\\nCounts:\")\n",
        "print(err_df[\"llm_problem_bin\"].value_counts())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW7tCHOKexSR",
        "outputId": "e68018cb-46a6-4deb-fd7a-a67986e61977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Fluency for human-error steps:\n",
            "llm_problem_bin\n",
            "0   -3.992727\n",
            "1   -3.833590\n",
            "Name: fluency, dtype: float64\n",
            "\n",
            "Counts:\n",
            "llm_problem_bin\n",
            "1    12\n",
            "0    12\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For steps where humans say “there is a problem,” both groups are quite fluent, and the LLM is slightly more likely to agree with humans when the step is less fluent.\n",
        "​\n",
        "\n",
        "What these numbers mean\n",
        "You restricted to steps with human_problem = 1 (humans see an error).\n",
        "\n",
        "Within those, you split by the LLM’s decision:\n",
        "\n",
        "llm_problem_bin = 1 (LLM also sees a problem): fluency ≈ ‑3.83.\n",
        "\n",
        "llm_problem_bin = 0 (LLM misses the problem): fluency ≈ ‑3.99.\n",
        "\n",
        "Remember: higher (less negative) = more fluent.\n",
        "\n",
        "So error steps where LLM agrees with humans are slightly more fluent than those where it misses the error.\n",
        "\n",
        "Interpretation for your bias question\n",
        "Among clearly erroneous steps, the LLM is not preferentially excusing the most fluent ones; if anything, it detects problems slightly better on more fluent text.\n",
        "\n",
        "With such a small sample (12 vs 12), these differences are tiny and not statistically strong, but they do not support the story “LLM over‑trusts very fluent wrong steps” on this slice.\n",
        "\n",
        "Combined with earlier results (disagreements less fluent overall), your current evidence suggests:\n",
        "\n",
        "The judge struggles more with rough, awkward steps, not with overly fluent ones."
      ],
      "metadata": {
        "id": "HQVPYvNygx6i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Saving important result :\n",
        "subset.to_csv(\"roscoe_step_judgments_raw.csv\", index=False)\n",
        "subset.to_json(\"roscoe_step_judgments_raw.jsonl\",\n",
        "               orient=\"records\", lines=True)\n",
        "print(\"Saved roscoe_step_judgments_raw.*\")\n",
        "analysis_df.to_csv(\"roscoe_analysis_features.csv\", index=False)\n",
        "analysis_df.to_json(\"roscoe_analysis_features.jsonl\",\n",
        "                    orient=\"records\", lines=True)\n",
        "print(\"Saved roscoe_analysis_features.*\")\n",
        "\n",
        "\n",
        "import json\n",
        "\n",
        "summary = {\n",
        "    \"n_steps\": int(len(analysis_df)),\n",
        "    \"agreement_rate\": float(analysis_df[\"agree\"].mean()),\n",
        "    \"avg_len_agree\": float(analysis_df.groupby(\"agree\")[\"step_len\"].mean().get(1, 0.0)),\n",
        "    \"avg_len_disagree\": float(analysis_df.groupby(\"agree\")[\"step_len\"].mean().get(0, 0.0)),\n",
        "    \"avg_flu_agree\": float(analysis_df.groupby(\"agree\")[\"fluency\"].mean().get(1, 0.0)),\n",
        "    \"avg_flu_disagree\": float(analysis_df.groupby(\"agree\")[\"fluency\"].mean().get(0, 0.0)),\n",
        "}\n",
        "\n",
        "with open(\"roscoe_summary.json\", \"w\") as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(\"Saved roscoe_summary.json\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7Cp_OZzfOvB",
        "outputId": "811e5efe-43f5-4c6f-d4db-873f987dd94a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved roscoe_step_judgments_raw.*\n",
            "Saved roscoe_analysis_features.*\n",
            "Saved roscoe_summary.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "***look directly at disagreement examples and label why the judge disagrees***"
      ],
      "metadata": {
        "id": "gclsyaQujteM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "disagree_df = analysis_df[analysis_df[\"agree\"] == 0].copy()\n",
        "print(\"Num disagreements:\", len(disagree_df))\n",
        "\n",
        "# Save them to inspect comfortably\n",
        "disagree_df.to_csv(\"roscoe_disagreements_for_manual_analysis.csv\", index=False)\n",
        "for i in range(5):\n",
        "    row = disagree_df.iloc[i]\n",
        "    print(\"=\"*80)\n",
        "    print(\"ID:\", row[\"id\"], \"step\", row[\"step_num\"])\n",
        "    print(\"Human_problem:\", row[\"human_problem\"],\n",
        "          \"LLM_problem:\", row[\"llm_problem_bin\"])\n",
        "    print(\"\\nCONTEXT:\\n\", row[\"context_block\"])\n",
        "    print(\"\\nSTEP:\\n\", row[\"step_text\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKY-LNzZjoUS",
        "outputId": "bf104226-2704-4ff9-86cf-09486957c7de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num disagreements: 58\n",
            "================================================================================\n",
            "ID: 172 step 5\n",
            "Human_problem: 0 LLM_problem: 1\n",
            "\n",
            "CONTEXT:\n",
            " For this task, you will be shown a CONTEXT with a \"Situation\" and a \"Claim\" about that \"Situation\". The \"Claim\" may or may not be supported by the \"Situation\". The Correct Relationship between the \"Claim\" and the \"Situation\" is provided.\n",
            "\n",
            "You will be shown a GENERATED RESPONSE generated from a bot, asked the question\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "You will be asked to judge the individual STEPS within the GENERATED RESPONSE. Interpret the questions to the best of your ability. Sometimes the generated response will refer to the \"Situation\" as a \"Premise\" and the \"Claim\" as a \"Hypothesis\". It will oftentimes be faster to read the \"Claim\" before the \"Situation\".\n",
            "\n",
            "CONTEXT:\n",
            "Situation (Premise): As of the census of 2000, there were 24,621 people, 9,029 households, and 6,284 families residing in the county.  The population density was 73 people per square mile (28/km²).  There were 12,064 housing units at an average density of 36 per square mile (14/km²).  The racial makeup of the county was 97.90% White (U.S. Census), 0.56% African American (U.S. Census), 0.15% Native American (U.S. Census), 0.28% Asian (U.S. Census), 0.02% Pacific Islander (U.S. Census), 0.36% from Race (United States Census), and 0.74% from two or more races. Hispanic (U.S. Census) or Latino (U.S. Census) of any race were 0.93% of the population. 21.3% were of English people, 16.5% Germans, 11.4% Irish people, 10.7% United States, 5.3% danish people and 5.3% Italian people ancestry according to Census 2000. How many more English people were there than Germans?\n",
            "\n",
            "Claim (Hypothesis): 4.8\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "Correct Relationship (Yes or No): yes\n",
            "\n",
            "\n",
            "\n",
            "STEP:\n",
            " 12.73675 people- 5.3% Danish people= 12.177 people.\n",
            "================================================================================\n",
            "ID: 378 step 2\n",
            "Human_problem: 0 LLM_problem: 1\n",
            "\n",
            "CONTEXT:\n",
            " For this task, you will be shown a CONTEXT with a \"Situation\" and a \"Claim\" about that \"Situation\". The \"Claim\" may or may not be supported by the \"Situation\". The Correct Relationship between the \"Claim\" and the \"Situation\" is provided.\n",
            "\n",
            "You will be shown a GENERATED RESPONSE generated from a bot, asked the question\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "You will be asked to judge the individual STEPS within the GENERATED RESPONSE. Interpret the questions to the best of your ability. Sometimes the generated response will refer to the \"Situation\" as a \"Premise\" and the \"Claim\" as a \"Hypothesis\". It will oftentimes be faster to read the \"Claim\" before the \"Situation\".\n",
            "\n",
            "CONTEXT:\n",
            "Situation (Premise): After a franchise record setting performance the Saints went to face another winless team, the St. Louis Rams. This time, however, the Rams pulled off one of the best upsets in the NFL season. A defense kept the Saints scoreless for the first half. The second the Rams sealed the deal with an interception return for 27 yards. With this the Saints fell to 5-3, however this would be the last time the Saints would lose in the regular season. How many losses did the Saints have coming into this game?\n",
            "\n",
            "Claim (Hypothesis): 2\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "Correct Relationship (Yes or No): yes\n",
            "\n",
            "\n",
            "\n",
            "STEP:\n",
            " The answer is 3.\n",
            "================================================================================\n",
            "ID: 201 step 2\n",
            "Human_problem: 0 LLM_problem: 1\n",
            "\n",
            "CONTEXT:\n",
            " For this task, you will be shown a CONTEXT with a \"Situation\" and a \"Claim\" about that \"Situation\". The \"Claim\" may or may not be supported by the \"Situation\". The Correct Relationship between the \"Claim\" and the \"Situation\" is provided.\n",
            "\n",
            "You will be shown a GENERATED RESPONSE generated from a bot, asked the question\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "You will be asked to judge the individual STEPS within the GENERATED RESPONSE. Interpret the questions to the best of your ability. Sometimes the generated response will refer to the \"Situation\" as a \"Premise\" and the \"Claim\" as a \"Hypothesis\". It will oftentimes be faster to read the \"Claim\" before the \"Situation\".\n",
            "\n",
            "CONTEXT:\n",
            "Situation (Premise): In 2012, Albanias GDP per capita stood at 30% of the European Union average, while GDP (PPP) per capita was 35%. Albania were one of three countries in Europe to record an economic growth in the first quarter of 2010 after the global financial crisis. The International Monetary Fund predicted 2.6% growth for Albania in 2010 and 3.2% in 2011. According to the Forbes , the Gross Domestic Product (GDP) was growing at 2.8%. The country had a trade balance of −9.7% and unemployment rate of 14.7%. The Foreign direct investment has increased significantly in recent years as the government has embarked on an ambitious program to improve the business climate through fiscal and legislative reforms. The economy is expected to expand in the near term, driven by a recovery in consumption and robust investments. Growth is projected to be 3.2% in 2016, 3.5% in 2017, and 3.8% in 2018. How many European countries other than Albania recorded an economic growth in the first quarter of 2010?\n",
            "\n",
            "Claim (Hypothesis): 2\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "Correct Relationship (Yes or No): yes\n",
            "\n",
            "\n",
            "\n",
            "STEP:\n",
            " The answer is 3.\n",
            "================================================================================\n",
            "ID: 171 step 7\n",
            "Human_problem: 0 LLM_problem: 1\n",
            "\n",
            "CONTEXT:\n",
            " For this task, you will be shown a CONTEXT with a \"Situation\" and a \"Claim\" about that \"Situation\". The \"Claim\" may or may not be supported by the \"Situation\". The Correct Relationship between the \"Claim\" and the \"Situation\" is provided.\n",
            "\n",
            "You will be shown a GENERATED RESPONSE generated from a bot, asked the question\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "You will be asked to judge the individual STEPS within the GENERATED RESPONSE. Interpret the questions to the best of your ability. Sometimes the generated response will refer to the \"Situation\" as a \"Premise\" and the \"Claim\" as a \"Hypothesis\". It will oftentimes be faster to read the \"Claim\" before the \"Situation\".\n",
            "\n",
            "CONTEXT:\n",
            "Situation (Premise): As of the census of 2000, there were 24,621 people, 9,029 households, and 6,284 families residing in the county.  The population density was 73 people per square mile (28/km²).  There were 12,064 housing units at an average density of 36 per square mile (14/km²).  The racial makeup of the county was 97.90% White (U.S. Census), 0.56% African American (U.S. Census), 0.15% Native American (U.S. Census), 0.28% Asian (U.S. Census), 0.02% Pacific Islander (U.S. Census), 0.36% from Race (United States Census), and 0.74% from two or more races. Hispanic (U.S. Census) or Latino (U.S. Census) of any race were 0.93% of the population. 21.3% were of English people, 16.5% Germans, 11.4% Irish people, 10.7% United States, 5.3% danish people and 5.3% Italian people ancestry according to Census 2000. How many more English people were there than Germans?\n",
            "\n",
            "Claim (Hypothesis): 4.8\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "Correct Relationship (Yes or No): yes\n",
            "\n",
            "\n",
            "\n",
            "STEP:\n",
            " English people- Germans= 19.357 people- 16.1185 people= 3.2385 people.\n",
            "================================================================================\n",
            "ID: 386 step 1\n",
            "Human_problem: 0 LLM_problem: 1\n",
            "\n",
            "CONTEXT:\n",
            " For this task, you will be shown a CONTEXT with a \"Situation\" and a \"Claim\" about that \"Situation\". The \"Claim\" may or may not be supported by the \"Situation\". The Correct Relationship between the \"Claim\" and the \"Situation\" is provided.\n",
            "\n",
            "You will be shown a GENERATED RESPONSE generated from a bot, asked the question\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "You will be asked to judge the individual STEPS within the GENERATED RESPONSE. Interpret the questions to the best of your ability. Sometimes the generated response will refer to the \"Situation\" as a \"Premise\" and the \"Claim\" as a \"Hypothesis\". It will oftentimes be faster to read the \"Claim\" before the \"Situation\".\n",
            "\n",
            "CONTEXT:\n",
            "Situation (Premise): The seat of the Archbishop of Karelia and All Finland is in Kuopio. The archbishop is the head of the church and the diocese. He is assisted in the diocese by a suffragan bishop known as the Bishop of Joensuu. Despite his title, the bishop is also seated at Kuopio. The word \"Karelia\" in the archbishop's title only refers to the Finnish Karelia. The current Archbishop, Leo Makkonen, was born in 1948. Before his appointment as the archbishop in 2001, he was the Metropolitan of Helsinki from 1996, and Metropolitan of Oulu from 1980. The current Bishop of Joensuu is Arseni, who took the position in 2005. The Diocese of Karelia has 22,000 church members in 12 parishes. The number of priests in the diocese is about 45, and churches and chapels total over 80. The diocese also includes the only orthodox monasteries in Finland. The Orthodox Church Museum of Finland also operates in Kuopio. How many officials are in the Karelian Diocese?\n",
            "\n",
            "Claim (Hypothesis): 45\n",
            "\n",
            "Is the Claim supported by the Situation?\n",
            "\n",
            "Correct Relationship (Yes or No): yes\n",
            "\n",
            "\n",
            "\n",
            "STEP:\n",
            " The current Archbishop, Leo Makkonen, was born in 1948.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the ROSCOE‑DROP stepwise sample, the LLM judge agreed with human step‑level annotations in about 71% of evaluated steps, showing reasonably high but imperfect alignment. Disagreements were not concentrated on especially long or highly fluent steps; on aggregate, disagreeing steps were slightly shorter and somewhat less fluent than agreeing ones, and among human‑error steps the LLM actually detected problems a bit more often when the text was more fluent. Qualitative inspection of disagreement cases revealed that most mismatches arose from differences in task interpretation and strictness—for example, the LLM re‑solving math questions and flagging numerically wrong answers or irrelevant but factual sentences as “problems” where human annotators had not, rather than from a clear bias toward fluent or verbose language.\n"
      ],
      "metadata": {
        "id": "JlQ9PQJNyxdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json, os\n",
        "\n",
        "# 1. Get the notebook filename (replace if needed)\n",
        "NB_NAME = \"Roscoe_drop.ipynb\"   # exact name as in your repo / Drive\n",
        "\n",
        "# 2. Load, remove metadata.widgets, save back\n",
        "with open(NB_NAME, \"r\", encoding=\"utf-8\") as f:\n",
        "    nb = json.load(f)\n",
        "\n",
        "if \"metadata\" in nb and \"widgets\" in nb[\"metadata\"]:\n",
        "    print(\"Removing metadata.widgets...\")\n",
        "    del nb[\"metadata\"][\"widgets\"]\n",
        "else:\n",
        "    print(\"No metadata.widgets found.\")\n",
        "\n",
        "with open(NB_NAME, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(nb, f)\n",
        "\n",
        "print(\"Cleaned notebook saved:\", NB_NAME)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "mqDBBuwu5wGt",
        "outputId": "660088e3-afdb-4e9a-86bb-93a84d540ed5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'Roscoe_drop.ipynb'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3180719998.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# 2. Load, remove metadata.widgets, save back\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNB_NAME\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Roscoe_drop.ipynb'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# List to find exact path/name\n",
        "!ls \"/content/drive/MyDrive\"\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "VGhbk-Sy55fb",
        "outputId": "faed9bd1-be1c-4df6-fa23-baa08c481051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-108599706.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# List to find exact path/name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ls \"/content/drive/MyDrive\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "5zz-iesbgvr_"
      }
    }
  ]
}